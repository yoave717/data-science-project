{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import requests\n",
    "import zipfile\n",
    "from datetime import timedelta, date\n",
    "import re\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from geopy.distance import geodesic\n",
    "import folium\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import KDTree\n",
    "from numba import jit\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# The stride client library, used to make the calls to the stride api\n",
    "# import stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "DATA_FOLDER = './2023_siri_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = './drive/MyDrive/2023_siri_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'G:\\\\My Drive\\\\2023_siri_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\yoave\\\\Documents\\\\OpenU\\\\Data Science\\\\data-science-project'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection\n",
    "\n",
    "Our data is sourced from the Open-Bus Stride ETL packages. These packages provide data in hourly intervals. The data includes information about bus locations, the nearest stop to each bus location, and correlations to the GTFS ride. This includes the date and time of scheduled arrival times, among other details.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Download Function\n",
    "\n",
    "In this cell, we define a function `download_files` to download and extract the data files for a given year.\n",
    "\n",
    "The function iterates over each day and hour in the year, constructs the corresponding file URL, and sends a GET request to download the file. If the file is successfully downloaded, it is saved in the 'compressed' directory and then extracted to the 'data' directory.\n",
    "\n",
    "If the file is not found on the server, its URL is added to a list of missing files, which is printed at the end of the function.\n",
    "\n",
    "The function also reads and writes the last downloaded date and hour from/to a file, allowing the download process to be resumed if it is interrupted.\n",
    "\n",
    "Finally, we call the function to download the files for the year 2023.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def daterange(start_date, end_date):\n",
    "    for n in range(int((end_date - start_date).days)):\n",
    "        yield start_date + timedelta(n)\n",
    "\n",
    "def download_files(year):\n",
    "    start_date = date(year, 1, 1)\n",
    "    end_date = date(year+1, 1, 1)\n",
    "    missing_files = []\n",
    "\n",
    "    if not os.path.exists(f'{DATA_FOLDER}/compressed'):\n",
    "        os.makedirs(f'{DATA_FOLDER}/compressed')\n",
    "    if not os.path.exists(f'{DATA_FOLDER}/data'):\n",
    "        os.makedirs(f'{DATA_FOLDER}/data')\n",
    "\n",
    "    # Read the start date and hour from a file\n",
    "    try:\n",
    "        with open(f'{DATA_FOLDER}/last_downloaded.txt', 'r') as f:\n",
    "            last_downloaded = f.read().strip()\n",
    "            start_date = date(int(last_downloaded[:4]), int(last_downloaded[5:7]), int(last_downloaded[8:10]))\n",
    "            start_hour = int(last_downloaded[11:13])\n",
    "    except FileNotFoundError:\n",
    "        start_hour = 0\n",
    "\n",
    "    for single_date in daterange(start_date, end_date):\n",
    "        for hour in range(start_hour, 24):\n",
    "            filename = f\"{single_date.strftime('%Y-%m-%d')}.{str(hour).zfill(2)}\"\n",
    "            url = f\"https://s3.eu-west-2.wasabisys.com/stride/stride-etl-packages/siri/{single_date.strftime('%Y/%m')}/{filename}.zip\"\n",
    "            response = requests.get(url)\n",
    "            if response.status_code == 200:\n",
    "                with open(f\"{DATA_FOLDER}/compressed/{filename}.zip\", 'wb') as f:\n",
    "                    f.write(response.content)\n",
    "                with zipfile.ZipFile(f\"{DATA_FOLDER}/compressed/{filename}.zip\", 'r') as zip_ref:\n",
    "                    if f\"{filename}.csv\" in zip_ref.namelist():\n",
    "                        zip_ref.extract(f\"{filename}.csv\", path=f'{DATA_FOLDER}/data')\n",
    "                # Save the current date and hour to a file\n",
    "                with open(f'{DATA_FOLDER}/last_downloaded.txt', 'w') as f:\n",
    "                    f.write(f\"{single_date.strftime('%Y-%m-%d')}.{str(hour).zfill(2)}\")\n",
    "            else:\n",
    "                missing_files.append(url)\n",
    "        start_hour = 0\n",
    "\n",
    "    print(\"Missing files:\")\n",
    "    for file in missing_files:\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download_files(2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keeping the data intact\n",
    "\n",
    "We might have a missing file in the data folder\n",
    "This function checks for missing files based on the compressed files folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def extract_missing_csv(data_folder):\n",
    "    zip_dir = f'{data_folder}/compressed'\n",
    "    csv_dir = f'{data_folder}/data'\n",
    "    # Get a list of all ZIP files\n",
    "    zip_files = glob.glob(f'{zip_dir}/*.zip')\n",
    "    zip_files.sort()\n",
    "\n",
    "    for zip_file in zip_files:\n",
    "        # Get the corresponding CSV file name\n",
    "        csv_file_name = os.path.basename(zip_file)[:-4] + '.csv'\n",
    "        csv_file_path = f'{csv_dir}/{csv_file_name}'\n",
    "        \n",
    "        # If the CSV file does not exist\n",
    "        if not os.path.exists(csv_file_path):\n",
    "            with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "                # Extract the CSV file\n",
    "                if csv_file_name in zip_ref.namelist():\n",
    "                    zip_ref.extract(csv_file_name, path=csv_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_missing_csv(DATA_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Segmentation\n",
    "\n",
    "To optimize memory usage and improve data accessibility, we will segment our data into chunks. Each new file will contain 1 million rows from the original dataset.\n",
    "\n",
    "Additionally, we will remove currently unnecessary columns to streamline our data. If required in the future, we can retrieve the omitted data using the Stride client.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def get_folder_size(folder_path):\n",
    "    total = 0\n",
    "    for path, dirs, files in os.walk(folder_path):\n",
    "        for f in files:\n",
    "            fp = os.path.join(path, f)\n",
    "            total += os.path.getsize(fp)\n",
    "    return total\n",
    "\n",
    "def extract_number(file_name):\n",
    "    match = re.search(r'output_(\\d+)_from_(.+)_at_(\\d+)_to_(.+)_at_(\\d+)', file_name)\n",
    "    return int(match.group(1)) if match else 0\n",
    "\n",
    "def extract_variables(file_name):\n",
    "    match = re.search(r'output_(\\d+)_from_(.+)_at_(\\d+)_to_(.+)_at_(\\d+)', file_name)\n",
    "    if match:\n",
    "        x = int(match.group(1))\n",
    "        start_file = match.group(2)\n",
    "        start_pos = int(match.group(3))\n",
    "        end_file = match.group(4)\n",
    "        end_pos = int(match.group(5))\n",
    "        return x, start_file, start_pos, end_file, end_pos\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def save_df_to_parquet(df, file_counter, start_file, start_pos, last_file, end_pos, files_to_remove, location):\n",
    "    print(f'Saving file {file_counter}...')\n",
    "    \n",
    "    dtypes = {\n",
    "        'id': 'string',\n",
    "        'bearing': 'int32',\n",
    "        'lat': 'float64',\n",
    "        'lon': 'float64',\n",
    "        'gtfs_stop_lat': 'float64',\n",
    "        'gtfs_stop_lon': 'float64',\n",
    "        }\n",
    "    \n",
    "    date_cols = ['recorded_at_time', 'siri_scheduled_start_time', 'gtfs_start_time', 'gtfs_end_time', 'gtfs_arrival_time', 'gtfs_departure_time']\n",
    "    \n",
    "    # converting types\n",
    "    df = df.astype(dtypes)\n",
    "    for col in date_cols:\n",
    "        df[col] = pd.to_datetime(df[col], format='%Y-%m-%dT%H:%M:%S%z')\n",
    "    \n",
    "    start_file_name = os.path.splitext(os.path.basename(start_file))[0]\n",
    "    last_file_name = os.path.splitext(os.path.basename(last_file))[0]\n",
    "\n",
    "    file_name = f'{location}/output_{file_counter}_from_{start_file_name}_at_{start_pos}_to_{last_file_name}_at_{end_pos}.parquet'\n",
    "\n",
    "    df.to_parquet(file_name, index=False)\n",
    "\n",
    "    # remove csv files\n",
    "    print(f'Processed files {os.path.basename(files_to_remove[0])} to {os.path.basename(files_to_remove[-2])}. Now Deleting...')\n",
    "    while len(files_to_remove) > 1:\n",
    "        os.remove(files_to_remove[0])\n",
    "        files_to_remove.pop(0)\n",
    "\n",
    "    if end_pos == -1 and files_to_remove:\n",
    "        os.remove(files_to_remove[0])\n",
    "        files_to_remove.pop(0)\n",
    "\n",
    "def process_files(folder_path, rows_per_file=10000000):\n",
    "    print(f\"Folder size before processing: {get_folder_size(folder_path)} bytes\")\n",
    "\n",
    "    output_files_folder_path = f'{folder_path}\\\\concatenated_data_parquet\\\\'\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    columns_to_drop = ['gtfs_agency_name', 'gtfs_stop_name', 'gtfs_route_long_name', 'gtfs_line_ref', 'gtfs_operator_ref', 'distance_from_siri_ride_stop_meters', 'distance_from_journey_start']\n",
    "\n",
    "    start_file = None\n",
    "    start_pos = None\n",
    "    last_file = None\n",
    "    end_pos = None\n",
    "\n",
    "    csv_files = glob.glob(f'{folder_path}\\\\data\\\\*.csv')\n",
    "\n",
    "    csv_files.sort()\n",
    "\n",
    "    file_counter = 1\n",
    "\n",
    "    output_files = glob.glob(f'{output_files_folder_path}output_*.parquet')\n",
    "\n",
    "    if output_files:\n",
    "        last_output_file = max(output_files, key=extract_number)\n",
    "        file_counter, start_file, start_pos, last_file, end_pos = extract_variables(last_output_file)\n",
    "        last_df = pd.read_parquet(last_output_file)\n",
    "        # If the last output file contains less than max rows, load it into df\n",
    "        if len(last_df) < rows_per_file:\n",
    "            df = last_df\n",
    "            os.remove(last_output_file)  # remove the last file as it will be rewritten later\n",
    "        else:\n",
    "            start_file = last_file\n",
    "            start_pos = end_pos\n",
    "            file_counter += 1\n",
    "    \n",
    "    if last_file is not None:\n",
    "        start_index = csv_files.index(f'{folder_path}\\\\data\\\\{last_file}.csv')\n",
    "    else:\n",
    "        start_index = 0\n",
    "        \n",
    "    files_to_remove = []\n",
    "    for file in csv_files[start_index:]:\n",
    "        files_to_remove.append(file)\n",
    "        # If the file is not empty\n",
    "        if os.path.getsize(file) > 0:\n",
    "            print(f'On file {file}')\n",
    "            try:\n",
    "                if end_pos is None:\n",
    "                    end_pos = 0\n",
    "                if start_file is None:\n",
    "                    start_file = file\n",
    "\n",
    "                temp_df = pd.read_csv(file, dtype='string', skiprows=range(1, end_pos))\n",
    "                temp_df['original_file'] = os.path.basename(file)  # Add the original file name to each row\n",
    "                last_file = file\n",
    "                \n",
    "                # Remove duplicates\n",
    "                temp_df = temp_df.drop_duplicates()\n",
    "\n",
    "                # Drop the unnecessary columns\n",
    "                temp_df = temp_df.drop(columns=columns_to_drop)\n",
    "                df = pd.concat([df, temp_df])\n",
    "                \n",
    "                # If the main DataFrame has reached max rows\n",
    "                print(df.shape[0])\n",
    "                if df.shape[0] >= rows_per_file:\n",
    "                    start_pos = end_pos\n",
    "                    end_pos = df.shape[0] - rows_per_file\n",
    "                    save_df_to_parquet(df[:rows_per_file], file_counter, start_file, start_pos, last_file, end_pos, files_to_remove, output_files_folder_path)\n",
    "\n",
    "                    # Keep the remaining rows in the DataFrame\n",
    "                    df = df[rows_per_file:]\n",
    "                    file_counter += 1\n",
    "                    start_file = file\n",
    "\n",
    "                if df.shape[0] == 0:\n",
    "                    start_file = None\n",
    "                    start_pos = None\n",
    "                    last_file = None\n",
    "                    end_pos = None\n",
    "                \n",
    "            except pd.errors.EmptyDataError:\n",
    "                print(f\"File {file} is empty or only contains a header.\")\n",
    "        \n",
    "    # Write the remaining rows in the DataFrame to a CSV file\n",
    "    if not df.empty:\n",
    "        save_df_to_parquet(df, file_counter, start_file, start_pos, last_file, -1, files_to_remove, output_files_folder_path)\n",
    "\n",
    "    print(f\"Folder size after processing: {get_folder_size(folder_path)} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: check if 2 df from parquet file has duplicates\n",
    "import os\n",
    "import pandas as pd\n",
    "df1 = pd.read_parquet(os.path.join(DATA_FOLDER, 'concatenated_data_parquet/output_1_from_2023-01-01.00_at_0_to_2023-01-03.05_at_69983.parquet'), columns=['id'])\n",
    "df2 = pd.read_parquet(os.path.join(DATA_FOLDER, 'concatenated_data_parquet/output_2_from_2023-01-01.00_at_69983_to_2023-01-05.12_at_244483.parquet'), columns=['id'])\n",
    "\n",
    "shared_index_df1 = df1['id'].tail(69983)\n",
    "shared_index_df2 = df2['id'][:69983]\n",
    "\n",
    "print(shared_index_df1, shared_index_df2)\n",
    "# Check if any IDs in df1 are also in df2\n",
    "common_ids = df2['id'].isin(df1['id'])\n",
    "\n",
    "# Check if there are any common IDs\n",
    "if common_ids.any():\n",
    "    print(\"There are common IDs in the dataframes.\")\n",
    "else:\n",
    "    print(\"There are no common IDs in the dataframes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = None\n",
    "df1 = None\n",
    "df2 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder size before processing: 891445519123 bytes\n",
      "On file G:\\My Drive\\2023_siri_data\\data\\2023-01-01.00.csv\n",
      "File G:\\My Drive\\2023_siri_data\\data\\2023-01-01.00.csv is empty or only contains a header.\n",
      "On file G:\\My Drive\\2023_siri_data\\data\\2023-01-01.01.csv\n",
      "File G:\\My Drive\\2023_siri_data\\data\\2023-01-01.01.csv is empty or only contains a header.\n",
      "On file G:\\My Drive\\2023_siri_data\\data\\2023-01-01.02.csv\n",
      "File G:\\My Drive\\2023_siri_data\\data\\2023-01-01.02.csv is empty or only contains a header.\n",
      "On file G:\\My Drive\\2023_siri_data\\data\\2023-01-01.03.csv\n",
      "File G:\\My Drive\\2023_siri_data\\data\\2023-01-01.03.csv is empty or only contains a header.\n",
      "On file G:\\My Drive\\2023_siri_data\\data\\2023-01-01.04.csv\n",
      "6\n",
      "On file G:\\My Drive\\2023_siri_data\\data\\2023-01-01.05.csv\n",
      "File G:\\My Drive\\2023_siri_data\\data\\2023-01-01.05.csv is empty or only contains a header.\n",
      "On file G:\\My Drive\\2023_siri_data\\data\\2023-01-01.06.csv\n",
      "21\n",
      "On file G:\\My Drive\\2023_siri_data\\data\\2023-01-01.07.csv\n",
      "193\n",
      "On file G:\\My Drive\\2023_siri_data\\data\\2023-01-01.08.csv\n",
      "86705\n",
      "On file G:\\My Drive\\2023_siri_data\\data\\2023-01-01.09.csv\n",
      "405859\n",
      "On file G:\\My Drive\\2023_siri_data\\data\\2023-01-01.10.csv\n",
      "705377\n",
      "On file G:\\My Drive\\2023_siri_data\\data\\2023-01-01.11.csv\n",
      "1002342\n",
      "On file G:\\My Drive\\2023_siri_data\\data\\2023-01-01.12.csv\n",
      "1298376\n",
      "On file G:\\My Drive\\2023_siri_data\\data\\2023-01-01.13.csv\n",
      "1622148\n",
      "On file G:\\My Drive\\2023_siri_data\\data\\2023-01-01.14.csv\n",
      "1963428\n",
      "On file G:\\My Drive\\2023_siri_data\\data\\2023-01-01.15.csv\n",
      "2312190\n",
      "On file G:\\My Drive\\2023_siri_data\\data\\2023-01-01.16.csv\n",
      "2681884\n",
      "On file G:\\My Drive\\2023_siri_data\\data\\2023-01-01.17.csv\n",
      "3028812\n",
      "On file G:\\My Drive\\2023_siri_data\\data\\2023-01-01.18.csv\n",
      "3347068\n",
      "On file G:\\My Drive\\2023_siri_data\\data\\2023-01-01.19.csv\n",
      "3619839\n",
      "On file G:\\My Drive\\2023_siri_data\\data\\2023-01-01.20.csv\n",
      "3848872\n",
      "On file G:\\My Drive\\2023_siri_data\\data\\2023-01-01.21.csv\n",
      "4032166\n",
      "On file G:\\My Drive\\2023_siri_data\\data\\2023-01-01.22.csv\n",
      "4178077\n",
      "On file G:\\My Drive\\2023_siri_data\\data\\2023-01-01.23.csv\n",
      "4282586\n",
      "On file G:\\My Drive\\2023_siri_data\\data\\2023-01-02.00.csv\n",
      "4332263\n",
      "On file G:\\My Drive\\2023_siri_data\\data\\2023-01-02.01.csv\n",
      "4343542\n",
      "On file G:\\My Drive\\2023_siri_data\\data\\2023-01-02.02.csv\n",
      "4347135\n",
      "On file G:\\My Drive\\2023_siri_data\\data\\2023-01-02.03.csv\n",
      "4349183\n",
      "On file G:\\My Drive\\2023_siri_data\\data\\2023-01-02.04.csv\n",
      "4354982\n",
      "On file G:\\My Drive\\2023_siri_data\\data\\2023-01-02.05.csv\n",
      "4440306\n",
      "On file G:\\My Drive\\2023_siri_data\\data\\2023-01-02.06.csv\n",
      "4684400\n",
      "On file G:\\My Drive\\2023_siri_data\\data\\2023-01-02.07.csv\n",
      "5053209\n",
      "On file G:\\My Drive\\2023_siri_data\\data\\2023-01-02.08.csv\n",
      "5438897\n",
      "On file G:\\My Drive\\2023_siri_data\\data\\2023-01-02.09.csv\n",
      "5792223\n",
      "On file G:\\My Drive\\2023_siri_data\\data\\2023-01-02.10.csv\n",
      "6111217\n",
      "On file G:\\My Drive\\2023_siri_data\\data\\2023-01-02.11.csv\n",
      "6424706\n",
      "On file G:\\My Drive\\2023_siri_data\\data\\2023-01-02.12.csv\n",
      "6739857\n",
      "On file G:\\My Drive\\2023_siri_data\\data\\2023-01-02.13.csv\n",
      "7083600\n",
      "On file G:\\My Drive\\2023_siri_data\\data\\2023-01-02.14.csv\n",
      "7439204\n",
      "On file G:\\My Drive\\2023_siri_data\\data\\2023-01-02.15.csv\n",
      "7813482\n",
      "On file G:\\My Drive\\2023_siri_data\\data\\2023-01-02.16.csv\n",
      "8203382\n",
      "On file G:\\My Drive\\2023_siri_data\\data\\2023-01-02.17.csv\n",
      "8586019\n",
      "On file G:\\My Drive\\2023_siri_data\\data\\2023-01-02.18.csv\n",
      "8926939\n",
      "On file G:\\My Drive\\2023_siri_data\\data\\2023-01-02.19.csv\n",
      "9221706\n",
      "On file G:\\My Drive\\2023_siri_data\\data\\2023-01-02.20.csv\n",
      "9461721\n",
      "On file G:\\My Drive\\2023_siri_data\\data\\2023-01-02.21.csv\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 73.7 MiB for an array with shape (9654148,) and data type object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mprocess_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATA_FOLDER\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[44], line 122\u001b[0m, in \u001b[0;36mprocess_files\u001b[1;34m(folder_path, rows_per_file)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;66;03m# Drop the unnecessary columns\u001b[39;00m\n\u001b[0;32m    121\u001b[0m temp_df \u001b[38;5;241m=\u001b[39m temp_df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39mcolumns_to_drop)\n\u001b[1;32m--> 122\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp_df\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# If the main DataFrame has reached max rows\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:395\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    382\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[0;32m    383\u001b[0m     objs,\n\u001b[0;32m    384\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    392\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    393\u001b[0m )\n\u001b[1;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:684\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    680\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m obj_labels\u001b[38;5;241m.\u001b[39mget_indexer(new_labels)\n\u001b[0;32m    682\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[1;32m--> 684\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[43mconcatenate_managers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmgrs_indexers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcat_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbm_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    688\u001b[0m     new_data\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\concat.py:180\u001b[0m, in \u001b[0;36mconcatenate_managers\u001b[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[0;32m    177\u001b[0m     values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(vals, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_1d_only_ea_dtype(blk\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;66;03m# TODO(EA2D): special-casing not needed with 2D EAs\u001b[39;00m\n\u001b[1;32m--> 180\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mconcat_compat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mea_compat_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m     values \u001b[38;5;241m=\u001b[39m ensure_block_shape(values, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\dtypes\\concat.py:83\u001b[0m, in \u001b[0;36mconcat_compat\u001b[1;34m(to_concat, axis, ea_compat_axis)\u001b[0m\n\u001b[0;32m     80\u001b[0m to_concat_eas \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSequence[ExtensionArray]\u001b[39m\u001b[38;5;124m\"\u001b[39m, to_concat)\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ea_compat_axis:\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;66;03m# We have 1D objects, that don't support axis keyword\u001b[39;00m\n\u001b[1;32m---> 83\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_concat_same_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_concat_eas\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_concat_same_type(to_concat_eas)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\arrays\\_mixins.py:238\u001b[0m, in \u001b[0;36mNDArrayBackedExtensionArray._concat_same_type\u001b[1;34m(cls, to_concat, axis)\u001b[0m\n\u001b[0;32m    235\u001b[0m     dtypes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;28mstr\u001b[39m(x\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m to_concat}\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_concat must have the same dtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, dtypes)\n\u001b[1;32m--> 238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_concat_same_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_concat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32marrays.pyx:189\u001b[0m, in \u001b[0;36mpandas._libs.arrays.NDArrayBacked._concat_same_type\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 73.7 MiB for an array with shape (9654148,) and data type object"
     ]
    }
   ],
   "source": [
    "process_files(DATA_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Examination\n",
    "\n",
    "In this phase, we will focus on analyzing a single bus line, specifically line 68, which operates from Kiryat Ono terminal to Tel-Aviv central station. Our analysis will be limited to the first month of 2023.\n",
    "\n",
    "Our primary goal is to identify instances of delays and subsequently investigate potential causes for these delays.\n",
    "\n",
    "To facilitate this, we will prepare a DataFrame that consolidates all relevant data pertaining to this bus line.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def create_filtered_df(parquet_dir, line_refs, limit=0, offset=0):\n",
    "    parquet_files = glob.glob(f'{parquet_dir}/output_*.parquet')\n",
    "\n",
    "    parquet_files.sort(key=extract_number)\n",
    "    \n",
    "    if limit > 0:\n",
    "        parquet_files = parquet_files[offset:offset+limit]\n",
    "    else:\n",
    "        parquet_files = parquet_files[offset:]\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    counter = 0\n",
    "\n",
    "    for file in parquet_files:\n",
    "        # Read the Parquet file\n",
    "        temp_df = pd.read_parquet(file, filters=[('siri_line_ref', 'in', line_refs)])\n",
    "        temp = temp_df.astype({'gtfs_stop_lat': float, 'gtfs_stop_lon': float, 'lat': float, 'lon': float})\n",
    "        df = pd.concat([df, temp_df])\n",
    "        counter += 1\n",
    "\n",
    "        if counter % 20 == 0:\n",
    "            print(f'Processed {counter} files. Current file: {os.path.basename(file)}')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_filtered_df(f'{DATA_FOLDER}/concatenated_data_parquet', ['28015'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting and Formatting Data\n",
    "\n",
    "In this step, we sort the dataframe `df` by 'siri_journey_ref' and 'recorded_at_time'. We also convert the 'gtfs_arrival_time' and 'recorded_at_time' columns to datetime format for easier manipulation in later steps.\n",
    "\n",
    "We then create two new dataframes:\n",
    "\n",
    "- `df_bus_journey_stops`: This dataframe is created by selecting specific columns from `df_sorted` and dropping duplicates. It contains information about the bus journey stops.\n",
    "\n",
    "- `df_locations`: This dataframe is created by excluding columns that start with 'gtfs' from `df_sorted`. It contains information about the bus locations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def process_dataframe(df):\n",
    "    df_sorted = df.sort_values(['siri_journey_ref', 'recorded_at_time'])\n",
    "    \n",
    "    bus_journey_cols = ['id','siri_journey_ref', 'siri_vehicle_ref', 'siri_stop_code', 'siri_stop_order', 'siri_operator_ref', 'siri_line_ref', 'gtfs_journey_ref', 'gtfs_start_time', 'gtfs_end_time', 'gtfs_stop_code', 'gtfs_stop_lat', 'gtfs_stop_lon', 'gtfs_stop_city', 'gtfs_arrival_time', 'gtfs_stop_sequence', 'gtfs_route_short_name', 'gtfs_route_direction', 'gtfs_route_mkt']\n",
    "    df_bus_journey_stops = df_sorted[bus_journey_cols].drop_duplicates()\n",
    "\n",
    "    # Remove rows where 'gtfs_stop_lat' or 'gtfs_stop_lon' is NaN\n",
    "    df_bus_journey_stops = df_bus_journey_stops.dropna(subset=['gtfs_stop_lat', 'gtfs_stop_lon'])\n",
    "\n",
    "    location_cols = [col for col in df_sorted.columns if not col.startswith('gtfs')]\n",
    "    df_locations = df_sorted[location_cols]\n",
    "\n",
    "     # Remove journeys where all locations have the same lat and lon\n",
    "    journey_counts = df_locations.groupby('siri_journey_ref')[['lat', 'lon']].nunique()\n",
    "    journeys_to_keep = journey_counts[(journey_counts['lat'] > 2) | (journey_counts['lon'] > 2)].index\n",
    "    df_locations = df_locations[df_locations['siri_journey_ref'].isin(journeys_to_keep)]\n",
    "    df_bus_journey_stops = df_bus_journey_stops[df_bus_journey_stops['siri_journey_ref'].isin(journeys_to_keep)]\n",
    "\n",
    "\n",
    "    return df_bus_journey_stops, df_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bus_journey_stops, df_locations = process_dataframe(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Distance and Speed\n",
    "\n",
    "In this step, we define a function `calculate_distance_and_speed` to calculate the distance and speed for each journey.\n",
    "\n",
    "- The function first calculates the distances between consecutive locations using the `geodesic` function from the `geopy.distance` module.\n",
    "- It then calculates the time difference between consecutive locations and uses this to calculate the speed.\n",
    "- Any `NaN` values in the 'speed', 'distance', and 'time_diff' columns are replaced with 0.\n",
    "\n",
    "Finally, we apply this function to our DataFrame `df_locations` using the `groupby` and `apply` methods, and reset the index.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_locations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 45\u001b[0m\n\u001b[0;32m     41\u001b[0m     df_locations\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df_locations\n\u001b[1;32m---> 45\u001b[0m df_locations \u001b[38;5;241m=\u001b[39m process_locations(\u001b[43mdf_locations\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_locations' is not defined"
     ]
    }
   ],
   "source": [
    "# Pre-calculate constants outside the function\n",
    "earth_radius = 6367 * 2 * np.pi\n",
    "\n",
    "@jit(nopython=True)\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "\n",
    "    # Convert coordinates to radians (vectorized)\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "\n",
    "    # Haversine formula (vectorized operations)\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = np.sin(dlat / 2.0) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2.0) ** 2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "\n",
    "    return earth_radius * c\n",
    "\n",
    "def calculate_distance_and_speed(group):\n",
    "    \n",
    "    lats = group['lat'].values\n",
    "    lons = group['lon'].values\n",
    "\n",
    "    # Vectorized haversine calculation\n",
    "    distances = haversine(lats[:-1], lons[:-1], lats[1:], lons[1:])\n",
    "\n",
    "    # Add distance and time difference columns\n",
    "    group['distance'] = np.append(distances, np.nan)\n",
    "    group['time_diff'] = (group['recorded_at_time'].shift(-1) - group['recorded_at_time']).dt.total_seconds() / 3600\n",
    "\n",
    "    # Calculate speed\n",
    "    group['speed'] = group['distance'] / np.maximum(group['time_diff'], 1e-9)\n",
    "\n",
    "    # Replace NaN values with 0\n",
    "    group['speed'] = np.nan_to_num(group['speed'])\n",
    "    group['distance'] = np.nan_to_num(group['distance'])\n",
    "    group['time_diff'] = np.nan_to_num(group['time_diff'])\n",
    "\n",
    "    return group\n",
    "\n",
    "def process_locations(df_locations):\n",
    "    df_locations = df_locations.groupby('siri_journey_ref').apply(calculate_distance_and_speed)\n",
    "    df_locations.reset_index(drop=True, inplace=True)\n",
    "    return df_locations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_locations = process_locations(df_locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Arrival Times\n",
    "\n",
    "In this step, we define several functions to calculate the estimated arrival times at each bus stop for each journey.\n",
    "\n",
    "- The `haversine` function calculates the distance between two points on the Earth's surface given their latitudes and longitudes.\n",
    "- The `calculate_bearing` function calculates the bearing between two points on the Earth's surface.\n",
    "- The `calculate_arrival_times` function uses the above two functions to estimate the arrival times at each bus stop for each journey. It takes into account the speed of the bus, the distance to the next stop, and the direction of the bus.\n",
    "\n",
    "An important part of the `calculate_arrival_times` function is the calculation of the 'moving_towards_stop' field. This field is a boolean that indicates whether the bus is moving towards or away from the stop. It is calculated by comparing the bearing of the bus to the bearing of the line from the bus to the stop. If the bus's bearing is within a certain range of the bearing to the stop, then the bus is considered to be moving towards the stop. This calculation is important because it allows us to distinguish between a bus that is approaching a stop and a bus that has already passed a stop.\n",
    "\n",
    "The 'distance_from_stop' field is the distance from the closest bus location to the stop. It is calculated using the `haversine` function.\n",
    "\n",
    "The 'estimated_arrival_time' field is the estimated time that the bus will arrive at the stop. It is calculated by adding the estimated time to the stop (which is the distance to the stop divided by the speed of the bus) to the time that the closest location was recorded. If the bus is moving away from the stop, the estimated time to the stop is subtracted from the recorded time instead.\n",
    "\n",
    "Finally, we call the `calculate_arrival_times` function to calculate the estimated arrival times for our data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mKernel is dead. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "@jit(nopython=True)\n",
    "def calculate_bearing(lat1, lon1, lat2, lon2):\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "\n",
    "    # Calculate the difference in longitudes\n",
    "    dlon = lon2 - lon1\n",
    "\n",
    "    # Calculate the bearing\n",
    "    x = np.sin(dlon) * np.cos(lat2)\n",
    "    y = np.cos(lat1) * np.sin(lat2) - np.sin(lat1) * np.cos(lat2) * np.cos(dlon)\n",
    "    bearing = np.degrees(np.arctan2(x, y))\n",
    "\n",
    "    # Normalize the bearing to be between 0 and 360\n",
    "    return (bearing + 360) % 360\n",
    "\n",
    "def calculate_arrival_times(df_locations, df_bus_journey_stops, bearing_threshold=15):\n",
    "    results = []\n",
    "\n",
    "    df_locations['speed'].replace(0, np.nan, inplace=True)\n",
    "\n",
    "    grouped_locations = df_locations.groupby('siri_journey_ref')\n",
    "\n",
    "    for journey, journey_locations in grouped_locations:\n",
    "        journey_stops = df_bus_journey_stops[df_bus_journey_stops['siri_journey_ref'] == journey]\n",
    "\n",
    "        # Skip the journey if it only has 2 or fewer stops\n",
    "        if len(journey_stops) <= 2:\n",
    "            continue\n",
    "        \n",
    "        journey_locations = journey_locations.sort_values('recorded_at_time')\n",
    "\n",
    "        # Interpolate to fill NaN values with the nearest non-NaN values\n",
    "        journey_locations['speed'].interpolate(method='nearest', limit_direction='both', inplace=True)\n",
    "\n",
    "        # Calculate the mean speed excluding the start and end points\n",
    "        mean_speed = journey_locations['speed'][1:-1].mean()\n",
    "\n",
    "        # Fill remaining NaN values at the start and end of the series with the mean speed\n",
    "        journey_locations['speed'].fillna(mean_speed, inplace=True)\n",
    "\n",
    "        latitudes = journey_locations['lat'].values\n",
    "        longitudes = journey_locations['lon'].values\n",
    "\n",
    "        journey_tree = KDTree(list(zip(latitudes, longitudes)), leafsize=4)\n",
    "\n",
    "        for i, stop in journey_stops.iterrows():\n",
    "            _, closest_location_idx = journey_tree.query((stop['gtfs_stop_lat'], stop['gtfs_stop_lon']))\n",
    "            closest_location = journey_locations.iloc[closest_location_idx]\n",
    "\n",
    "            bearing = calculate_bearing(closest_location['lat'], closest_location['lon'],\n",
    "                                         stop['gtfs_stop_lat'], stop['gtfs_stop_lon'])\n",
    "\n",
    "            distance_to_stop = haversine(closest_location['lat'], closest_location['lon'],\n",
    "                                          stop['gtfs_stop_lat'], stop['gtfs_stop_lon'])\n",
    "\n",
    "            moving_towards_stop = abs(closest_location['bearing'] - bearing) > bearing_threshold\n",
    "\n",
    "            estimated_time_to_stop = (distance_to_stop / closest_location['speed']) * 3600\n",
    "\n",
    "            if not moving_towards_stop:\n",
    "                estimated_arrival_time = closest_location['recorded_at_time'] - pd.Timedelta(seconds=estimated_time_to_stop)\n",
    "            else:\n",
    "                estimated_arrival_time = closest_location['recorded_at_time'] + pd.Timedelta(seconds=estimated_time_to_stop)\n",
    "\n",
    "            results.append({\n",
    "                'siri_journey_ref': journey,\n",
    "                'gtfs_stop_code': stop['gtfs_stop_code'],\n",
    "                'closest_location': closest_location['id'],\n",
    "                'closest_location_lat': closest_location['lat'],\n",
    "                'closest_location_lon': closest_location['lon'],\n",
    "                'closet_location_speed': closest_location['speed'],\n",
    "                'closest_location_bearing': closest_location['bearing'],\n",
    "                'recorded_at_time': closest_location['recorded_at_time'],\n",
    "                'distance_from_stop': distance_to_stop,\n",
    "                'scheduled_arrival_time': stop['gtfs_arrival_time'],\n",
    "                'estimated_arrival_time': estimated_arrival_time,\n",
    "                'moving_towards_stop': moving_towards_stop,\n",
    "                'arrival_time_diff': estimated_arrival_time - stop['gtfs_arrival_time']\n",
    "            })\n",
    "\n",
    "    df_results = pd.DataFrame(results)\n",
    "    df_results = pd.merge(df_bus_journey_stops, df_results, on=['siri_journey_ref', 'gtfs_stop_code'])\n",
    "\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = calculate_arrival_times(df_locations, df_bus_journey_stops, bearing_threshold=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Bus Locations and Stops for a Specific Journey\n",
    "\n",
    "In this cell, we are creating a map to visualize the bus locations and stops for a specific journey. This map is centered at the mean latitude and longitude of the journey's locations.\n",
    "\n",
    "Each bus location is marked with a blue icon, and each stop location is marked with a red icon. If the bus is moving towards the stop, the corresponding marker's popup will show 'Moving Towards Stop: Yes', otherwise it will show 'Moving Towards Stop: No'.\n",
    "\n",
    "We also draw a blue line connecting all the bus locations and a red line connecting all the stop locations. This visual representation helps us to better understand the 'moving_towards_stop' field that was calculated earlier.\n",
    "\n",
    "By visualizing a specific journey, we can manually verify if the 'moving_towards_stop' calculation is correct.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mKernel is dead. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def plot_journey(siri_journey_ref, results):\n",
    "    # Filter the results for the specified journey\n",
    "    journey_results = results[results['siri_journey_ref'] == siri_journey_ref]\n",
    "\n",
    "    # Create a map centered at the mean latitude and longitude of the journey's locations\n",
    "    m = folium.Map(location=[journey_results['closest_location_lat'].mean(), journey_results['closest_location_lon'].mean()], zoom_start=13)\n",
    "\n",
    "    # Add a marker for each bus location\n",
    "    for _, row in journey_results.iterrows():\n",
    "        # Determine whether the bus has already left the stop\n",
    "        moving_towards_stop = 'Yes' if row['moving_towards_stop'] else 'No'\n",
    "        \n",
    "        # Add a marker with a popup showing whether the bus has left the stop\n",
    "        folium.Marker([row['closest_location_lat'], row['closest_location_lon']], \n",
    "                      icon=folium.Icon(color=\"blue\"), \n",
    "                      popup=f'Moving Towards Stop: {moving_towards_stop}').add_to(m)\n",
    "        \n",
    "    # Add a marker for each stop location\n",
    "    for _, row in journey_results.iterrows():\n",
    "        folium.Marker([row['gtfs_stop_lat'], row['gtfs_stop_lon']], icon=folium.Icon(color=\"red\")).add_to(m)\n",
    "\n",
    "    # Add a line for the bus locations\n",
    "    bus_locations = journey_results[['closest_location_lat', 'closest_location_lon']].values.tolist()\n",
    "    folium.PolyLine(bus_locations, color=\"blue\").add_to(m)\n",
    "\n",
    "    # Add a line for the stop locations\n",
    "    stop_locations = journey_results[['gtfs_stop_lat', 'gtfs_stop_lon']].values.tolist()\n",
    "    folium.PolyLine(stop_locations, color=\"red\").add_to(m)\n",
    "\n",
    "    # Display the map\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
       "&lt;html&gt;\n",
       "&lt;head&gt;\n",
       "    \n",
       "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
       "    \n",
       "        &lt;script&gt;\n",
       "            L_NO_TOUCH = false;\n",
       "            L_DISABLE_3D = false;\n",
       "        &lt;/script&gt;\n",
       "    \n",
       "    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n",
       "    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://code.jquery.com/jquery-3.7.1.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
       "    \n",
       "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
       "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
       "            &lt;style&gt;\n",
       "                #map_9d2f5dc51a2a2f2e025514c9394e72f9 {\n",
       "                    position: relative;\n",
       "                    width: 100.0%;\n",
       "                    height: 100.0%;\n",
       "                    left: 0.0%;\n",
       "                    top: 0.0%;\n",
       "                }\n",
       "                .leaflet-container { font-size: 1rem; }\n",
       "            &lt;/style&gt;\n",
       "        \n",
       "&lt;/head&gt;\n",
       "&lt;body&gt;\n",
       "    \n",
       "    \n",
       "            &lt;div class=&quot;folium-map&quot; id=&quot;map_9d2f5dc51a2a2f2e025514c9394e72f9&quot; &gt;&lt;/div&gt;\n",
       "        \n",
       "&lt;/body&gt;\n",
       "&lt;script&gt;\n",
       "    \n",
       "    \n",
       "            var map_9d2f5dc51a2a2f2e025514c9394e72f9 = L.map(\n",
       "                &quot;map_9d2f5dc51a2a2f2e025514c9394e72f9&quot;,\n",
       "                {\n",
       "                    center: [32.06092073333334, 34.855879333333334],\n",
       "                    crs: L.CRS.EPSG3857,\n",
       "                    zoom: 13,\n",
       "                    zoomControl: true,\n",
       "                    preferCanvas: false,\n",
       "                }\n",
       "            );\n",
       "\n",
       "            \n",
       "\n",
       "        \n",
       "    \n",
       "            var tile_layer_0c095db3c177f2634ac84352880cd70b = L.tileLayer(\n",
       "                &quot;https://tile.openstreetmap.org/{z}/{x}/{y}.png&quot;,\n",
       "                {&quot;attribution&quot;: &quot;\\u0026copy; \\u003ca href=\\&quot;https://www.openstreetmap.org/copyright\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e contributors&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 19, &quot;maxZoom&quot;: 19, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
       "            );\n",
       "        \n",
       "    \n",
       "            tile_layer_0c095db3c177f2634ac84352880cd70b.addTo(map_9d2f5dc51a2a2f2e025514c9394e72f9);\n",
       "        \n",
       "    \n",
       "            var marker_65ab7985ff4151aeadda7afa403f0cc3 = L.marker(\n",
       "                [32.0825, 34.845043],\n",
       "                {}\n",
       "            ).addTo(map_9d2f5dc51a2a2f2e025514c9394e72f9);\n",
       "        \n",
       "    \n",
       "            var icon_2c1ee01cec6b1a6a18dd8405bac2fef9 = L.AwesomeMarkers.icon(\n",
       "                {&quot;extraClasses&quot;: &quot;fa-rotate-0&quot;, &quot;icon&quot;: &quot;info-sign&quot;, &quot;iconColor&quot;: &quot;white&quot;, &quot;markerColor&quot;: &quot;blue&quot;, &quot;prefix&quot;: &quot;glyphicon&quot;}\n",
       "            );\n",
       "            marker_65ab7985ff4151aeadda7afa403f0cc3.setIcon(icon_2c1ee01cec6b1a6a18dd8405bac2fef9);\n",
       "        \n",
       "    \n",
       "        var popup_bd5703c34bf94b012b2fa5a68df09925 = L.popup({&quot;maxWidth&quot;: &quot;100%&quot;});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_89212e225f20a07b8133caab7bb44032 = $(`&lt;div id=&quot;html_89212e225f20a07b8133caab7bb44032&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Moving Towards Stop: Yes&lt;/div&gt;`)[0];\n",
       "                popup_bd5703c34bf94b012b2fa5a68df09925.setContent(html_89212e225f20a07b8133caab7bb44032);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_65ab7985ff4151aeadda7afa403f0cc3.bindPopup(popup_bd5703c34bf94b012b2fa5a68df09925)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var marker_782a33268c37b44df8181a777a0bb7a1 = L.marker(\n",
       "                [32.07529, 34.843635],\n",
       "                {}\n",
       "            ).addTo(map_9d2f5dc51a2a2f2e025514c9394e72f9);\n",
       "        \n",
       "    \n",
       "            var icon_c72e266375331c5b558ddb074b2536da = L.AwesomeMarkers.icon(\n",
       "                {&quot;extraClasses&quot;: &quot;fa-rotate-0&quot;, &quot;icon&quot;: &quot;info-sign&quot;, &quot;iconColor&quot;: &quot;white&quot;, &quot;markerColor&quot;: &quot;blue&quot;, &quot;prefix&quot;: &quot;glyphicon&quot;}\n",
       "            );\n",
       "            marker_782a33268c37b44df8181a777a0bb7a1.setIcon(icon_c72e266375331c5b558ddb074b2536da);\n",
       "        \n",
       "    \n",
       "        var popup_7a9086c9bb6553ccee37e994a1ddbfd4 = L.popup({&quot;maxWidth&quot;: &quot;100%&quot;});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_e89dadb2456e179bced2e2d8acf090df = $(`&lt;div id=&quot;html_e89dadb2456e179bced2e2d8acf090df&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Moving Towards Stop: No&lt;/div&gt;`)[0];\n",
       "                popup_7a9086c9bb6553ccee37e994a1ddbfd4.setContent(html_e89dadb2456e179bced2e2d8acf090df);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_782a33268c37b44df8181a777a0bb7a1.bindPopup(popup_7a9086c9bb6553ccee37e994a1ddbfd4)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var marker_62187fa08a349f77e517fb4cdb6cc556 = L.marker(\n",
       "                [32.068443, 34.840351],\n",
       "                {}\n",
       "            ).addTo(map_9d2f5dc51a2a2f2e025514c9394e72f9);\n",
       "        \n",
       "    \n",
       "            var icon_3c52e09c1a6bee3230246ba8d380b978 = L.AwesomeMarkers.icon(\n",
       "                {&quot;extraClasses&quot;: &quot;fa-rotate-0&quot;, &quot;icon&quot;: &quot;info-sign&quot;, &quot;iconColor&quot;: &quot;white&quot;, &quot;markerColor&quot;: &quot;blue&quot;, &quot;prefix&quot;: &quot;glyphicon&quot;}\n",
       "            );\n",
       "            marker_62187fa08a349f77e517fb4cdb6cc556.setIcon(icon_3c52e09c1a6bee3230246ba8d380b978);\n",
       "        \n",
       "    \n",
       "        var popup_6ad5c9a5a1ba73d55486fc44dc3617b0 = L.popup({&quot;maxWidth&quot;: &quot;100%&quot;});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_060d90bd883e3b4c71cb512dc9812a99 = $(`&lt;div id=&quot;html_060d90bd883e3b4c71cb512dc9812a99&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Moving Towards Stop: No&lt;/div&gt;`)[0];\n",
       "                popup_6ad5c9a5a1ba73d55486fc44dc3617b0.setContent(html_060d90bd883e3b4c71cb512dc9812a99);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_62187fa08a349f77e517fb4cdb6cc556.bindPopup(popup_6ad5c9a5a1ba73d55486fc44dc3617b0)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var marker_238b317697c223482a84cd941c84e449 = L.marker(\n",
       "                [32.064876, 34.84473],\n",
       "                {}\n",
       "            ).addTo(map_9d2f5dc51a2a2f2e025514c9394e72f9);\n",
       "        \n",
       "    \n",
       "            var icon_0beffd164677435051fb981e113f762a = L.AwesomeMarkers.icon(\n",
       "                {&quot;extraClasses&quot;: &quot;fa-rotate-0&quot;, &quot;icon&quot;: &quot;info-sign&quot;, &quot;iconColor&quot;: &quot;white&quot;, &quot;markerColor&quot;: &quot;blue&quot;, &quot;prefix&quot;: &quot;glyphicon&quot;}\n",
       "            );\n",
       "            marker_238b317697c223482a84cd941c84e449.setIcon(icon_0beffd164677435051fb981e113f762a);\n",
       "        \n",
       "    \n",
       "        var popup_3d5f4a86958810e320ee120f430b9aa9 = L.popup({&quot;maxWidth&quot;: &quot;100%&quot;});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_57466c164d8954c8e0594523cbc9f8ac = $(`&lt;div id=&quot;html_57466c164d8954c8e0594523cbc9f8ac&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Moving Towards Stop: No&lt;/div&gt;`)[0];\n",
       "                popup_3d5f4a86958810e320ee120f430b9aa9.setContent(html_57466c164d8954c8e0594523cbc9f8ac);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_238b317697c223482a84cd941c84e449.bindPopup(popup_3d5f4a86958810e320ee120f430b9aa9)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var marker_3e82072f3ca1798c36bce81f4a927985 = L.marker(\n",
       "                [32.066123, 34.849441],\n",
       "                {}\n",
       "            ).addTo(map_9d2f5dc51a2a2f2e025514c9394e72f9);\n",
       "        \n",
       "    \n",
       "            var icon_42bf5b2fb8955ac5c4fd8044993a7097 = L.AwesomeMarkers.icon(\n",
       "                {&quot;extraClasses&quot;: &quot;fa-rotate-0&quot;, &quot;icon&quot;: &quot;info-sign&quot;, &quot;iconColor&quot;: &quot;white&quot;, &quot;markerColor&quot;: &quot;blue&quot;, &quot;prefix&quot;: &quot;glyphicon&quot;}\n",
       "            );\n",
       "            marker_3e82072f3ca1798c36bce81f4a927985.setIcon(icon_42bf5b2fb8955ac5c4fd8044993a7097);\n",
       "        \n",
       "    \n",
       "        var popup_a04cef8caa48544430eb2662f93db914 = L.popup({&quot;maxWidth&quot;: &quot;100%&quot;});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_9318a19a0abbc004e432c38edabff3b9 = $(`&lt;div id=&quot;html_9318a19a0abbc004e432c38edabff3b9&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Moving Towards Stop: No&lt;/div&gt;`)[0];\n",
       "                popup_a04cef8caa48544430eb2662f93db914.setContent(html_9318a19a0abbc004e432c38edabff3b9);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_3e82072f3ca1798c36bce81f4a927985.bindPopup(popup_a04cef8caa48544430eb2662f93db914)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var marker_009ea569cf86e90afafc58476948a646 = L.marker(\n",
       "                [32.065547, 34.854652],\n",
       "                {}\n",
       "            ).addTo(map_9d2f5dc51a2a2f2e025514c9394e72f9);\n",
       "        \n",
       "    \n",
       "            var icon_f64f14b566f7d7f2212b6f821cdf23e7 = L.AwesomeMarkers.icon(\n",
       "                {&quot;extraClasses&quot;: &quot;fa-rotate-0&quot;, &quot;icon&quot;: &quot;info-sign&quot;, &quot;iconColor&quot;: &quot;white&quot;, &quot;markerColor&quot;: &quot;blue&quot;, &quot;prefix&quot;: &quot;glyphicon&quot;}\n",
       "            );\n",
       "            marker_009ea569cf86e90afafc58476948a646.setIcon(icon_f64f14b566f7d7f2212b6f821cdf23e7);\n",
       "        \n",
       "    \n",
       "        var popup_1ce6bfd5c0bcd82d423d1f065d38fde7 = L.popup({&quot;maxWidth&quot;: &quot;100%&quot;});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_e608f26882bfcca967ebe9056769584b = $(`&lt;div id=&quot;html_e608f26882bfcca967ebe9056769584b&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Moving Towards Stop: No&lt;/div&gt;`)[0];\n",
       "                popup_1ce6bfd5c0bcd82d423d1f065d38fde7.setContent(html_e608f26882bfcca967ebe9056769584b);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_009ea569cf86e90afafc58476948a646.bindPopup(popup_1ce6bfd5c0bcd82d423d1f065d38fde7)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var marker_21dc5e9bc70c93ed97c01272c2d030e0 = L.marker(\n",
       "                [32.063648, 34.857154],\n",
       "                {}\n",
       "            ).addTo(map_9d2f5dc51a2a2f2e025514c9394e72f9);\n",
       "        \n",
       "    \n",
       "            var icon_e8ed89e9062655f0b6659ca1bc355c94 = L.AwesomeMarkers.icon(\n",
       "                {&quot;extraClasses&quot;: &quot;fa-rotate-0&quot;, &quot;icon&quot;: &quot;info-sign&quot;, &quot;iconColor&quot;: &quot;white&quot;, &quot;markerColor&quot;: &quot;blue&quot;, &quot;prefix&quot;: &quot;glyphicon&quot;}\n",
       "            );\n",
       "            marker_21dc5e9bc70c93ed97c01272c2d030e0.setIcon(icon_e8ed89e9062655f0b6659ca1bc355c94);\n",
       "        \n",
       "    \n",
       "        var popup_30e7f76075c01cbd0947376d97a65640 = L.popup({&quot;maxWidth&quot;: &quot;100%&quot;});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_79a68612c6d995a634b6b1e8bb9a4c3d = $(`&lt;div id=&quot;html_79a68612c6d995a634b6b1e8bb9a4c3d&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Moving Towards Stop: Yes&lt;/div&gt;`)[0];\n",
       "                popup_30e7f76075c01cbd0947376d97a65640.setContent(html_79a68612c6d995a634b6b1e8bb9a4c3d);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_21dc5e9bc70c93ed97c01272c2d030e0.bindPopup(popup_30e7f76075c01cbd0947376d97a65640)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var marker_4daa20a205662f0fda2954514582cb43 = L.marker(\n",
       "                [32.063495, 34.861362],\n",
       "                {}\n",
       "            ).addTo(map_9d2f5dc51a2a2f2e025514c9394e72f9);\n",
       "        \n",
       "    \n",
       "            var icon_9d6b9b758aed7ed1360401386874b794 = L.AwesomeMarkers.icon(\n",
       "                {&quot;extraClasses&quot;: &quot;fa-rotate-0&quot;, &quot;icon&quot;: &quot;info-sign&quot;, &quot;iconColor&quot;: &quot;white&quot;, &quot;markerColor&quot;: &quot;blue&quot;, &quot;prefix&quot;: &quot;glyphicon&quot;}\n",
       "            );\n",
       "            marker_4daa20a205662f0fda2954514582cb43.setIcon(icon_9d6b9b758aed7ed1360401386874b794);\n",
       "        \n",
       "    \n",
       "        var popup_aeefbb49d215d0de702e7546bb357355 = L.popup({&quot;maxWidth&quot;: &quot;100%&quot;});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_18b4b986f3c0ad1219114d082661081c = $(`&lt;div id=&quot;html_18b4b986f3c0ad1219114d082661081c&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Moving Towards Stop: No&lt;/div&gt;`)[0];\n",
       "                popup_aeefbb49d215d0de702e7546bb357355.setContent(html_18b4b986f3c0ad1219114d082661081c);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_4daa20a205662f0fda2954514582cb43.bindPopup(popup_aeefbb49d215d0de702e7546bb357355)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var marker_7862a690d9ef25083a99714f05df3656 = L.marker(\n",
       "                [32.060867, 34.86301],\n",
       "                {}\n",
       "            ).addTo(map_9d2f5dc51a2a2f2e025514c9394e72f9);\n",
       "        \n",
       "    \n",
       "            var icon_61690badc88d45d159fd7e7cbc5ede72 = L.AwesomeMarkers.icon(\n",
       "                {&quot;extraClasses&quot;: &quot;fa-rotate-0&quot;, &quot;icon&quot;: &quot;info-sign&quot;, &quot;iconColor&quot;: &quot;white&quot;, &quot;markerColor&quot;: &quot;blue&quot;, &quot;prefix&quot;: &quot;glyphicon&quot;}\n",
       "            );\n",
       "            marker_7862a690d9ef25083a99714f05df3656.setIcon(icon_61690badc88d45d159fd7e7cbc5ede72);\n",
       "        \n",
       "    \n",
       "        var popup_12d67a8f3b6e58cf2e92aff1e2d27e6c = L.popup({&quot;maxWidth&quot;: &quot;100%&quot;});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_bd158d83121188546962da38d5c1ba46 = $(`&lt;div id=&quot;html_bd158d83121188546962da38d5c1ba46&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Moving Towards Stop: No&lt;/div&gt;`)[0];\n",
       "                popup_12d67a8f3b6e58cf2e92aff1e2d27e6c.setContent(html_bd158d83121188546962da38d5c1ba46);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_7862a690d9ef25083a99714f05df3656.bindPopup(popup_12d67a8f3b6e58cf2e92aff1e2d27e6c)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var marker_a34573d0858c2d2a6236fa2a32846915 = L.marker(\n",
       "                [32.057689, 34.864395],\n",
       "                {}\n",
       "            ).addTo(map_9d2f5dc51a2a2f2e025514c9394e72f9);\n",
       "        \n",
       "    \n",
       "            var icon_83c5b567e9a0ed89fd7aca94c5ed9d21 = L.AwesomeMarkers.icon(\n",
       "                {&quot;extraClasses&quot;: &quot;fa-rotate-0&quot;, &quot;icon&quot;: &quot;info-sign&quot;, &quot;iconColor&quot;: &quot;white&quot;, &quot;markerColor&quot;: &quot;blue&quot;, &quot;prefix&quot;: &quot;glyphicon&quot;}\n",
       "            );\n",
       "            marker_a34573d0858c2d2a6236fa2a32846915.setIcon(icon_83c5b567e9a0ed89fd7aca94c5ed9d21);\n",
       "        \n",
       "    \n",
       "        var popup_f426e6eb267a94f0bf582321b9c61e74 = L.popup({&quot;maxWidth&quot;: &quot;100%&quot;});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_2aa4e1a94e432a57feaaa7fc86602141 = $(`&lt;div id=&quot;html_2aa4e1a94e432a57feaaa7fc86602141&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Moving Towards Stop: Yes&lt;/div&gt;`)[0];\n",
       "                popup_f426e6eb267a94f0bf582321b9c61e74.setContent(html_2aa4e1a94e432a57feaaa7fc86602141);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_a34573d0858c2d2a6236fa2a32846915.bindPopup(popup_f426e6eb267a94f0bf582321b9c61e74)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var marker_19790daff2caf5f51ced530693ec1dc8 = L.marker(\n",
       "                [32.054138, 34.864418],\n",
       "                {}\n",
       "            ).addTo(map_9d2f5dc51a2a2f2e025514c9394e72f9);\n",
       "        \n",
       "    \n",
       "            var icon_ebcc297f3ff30b42b3382ec7c2b4e310 = L.AwesomeMarkers.icon(\n",
       "                {&quot;extraClasses&quot;: &quot;fa-rotate-0&quot;, &quot;icon&quot;: &quot;info-sign&quot;, &quot;iconColor&quot;: &quot;white&quot;, &quot;markerColor&quot;: &quot;blue&quot;, &quot;prefix&quot;: &quot;glyphicon&quot;}\n",
       "            );\n",
       "            marker_19790daff2caf5f51ced530693ec1dc8.setIcon(icon_ebcc297f3ff30b42b3382ec7c2b4e310);\n",
       "        \n",
       "    \n",
       "        var popup_a239d1cd623c3a8d32597d3c5dbc983b = L.popup({&quot;maxWidth&quot;: &quot;100%&quot;});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_4ef0cef1c6055a46cff98ad76c4a2393 = $(`&lt;div id=&quot;html_4ef0cef1c6055a46cff98ad76c4a2393&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Moving Towards Stop: Yes&lt;/div&gt;`)[0];\n",
       "                popup_a239d1cd623c3a8d32597d3c5dbc983b.setContent(html_4ef0cef1c6055a46cff98ad76c4a2393);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_19790daff2caf5f51ced530693ec1dc8.bindPopup(popup_a239d1cd623c3a8d32597d3c5dbc983b)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var marker_d63b4000a12f46d9c5f35af83593d266 = L.marker(\n",
       "                [32.047882, 34.865272],\n",
       "                {}\n",
       "            ).addTo(map_9d2f5dc51a2a2f2e025514c9394e72f9);\n",
       "        \n",
       "    \n",
       "            var icon_644a9fe2c293ae5bf9b57174ca4e0c61 = L.AwesomeMarkers.icon(\n",
       "                {&quot;extraClasses&quot;: &quot;fa-rotate-0&quot;, &quot;icon&quot;: &quot;info-sign&quot;, &quot;iconColor&quot;: &quot;white&quot;, &quot;markerColor&quot;: &quot;blue&quot;, &quot;prefix&quot;: &quot;glyphicon&quot;}\n",
       "            );\n",
       "            marker_d63b4000a12f46d9c5f35af83593d266.setIcon(icon_644a9fe2c293ae5bf9b57174ca4e0c61);\n",
       "        \n",
       "    \n",
       "        var popup_9023ea8969bfac01495e44bb19a8a6cc = L.popup({&quot;maxWidth&quot;: &quot;100%&quot;});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_7240f4468d6ff01dcd753755a537f314 = $(`&lt;div id=&quot;html_7240f4468d6ff01dcd753755a537f314&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Moving Towards Stop: Yes&lt;/div&gt;`)[0];\n",
       "                popup_9023ea8969bfac01495e44bb19a8a6cc.setContent(html_7240f4468d6ff01dcd753755a537f314);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_d63b4000a12f46d9c5f35af83593d266.bindPopup(popup_9023ea8969bfac01495e44bb19a8a6cc)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var marker_623549951b8d75a36be2e6db8abb1916 = L.marker(\n",
       "                [32.049659, 34.856235],\n",
       "                {}\n",
       "            ).addTo(map_9d2f5dc51a2a2f2e025514c9394e72f9);\n",
       "        \n",
       "    \n",
       "            var icon_12227ee4cfc76bb6cf5c41027d853e67 = L.AwesomeMarkers.icon(\n",
       "                {&quot;extraClasses&quot;: &quot;fa-rotate-0&quot;, &quot;icon&quot;: &quot;info-sign&quot;, &quot;iconColor&quot;: &quot;white&quot;, &quot;markerColor&quot;: &quot;blue&quot;, &quot;prefix&quot;: &quot;glyphicon&quot;}\n",
       "            );\n",
       "            marker_623549951b8d75a36be2e6db8abb1916.setIcon(icon_12227ee4cfc76bb6cf5c41027d853e67);\n",
       "        \n",
       "    \n",
       "        var popup_ea25f34ea9a3bc035df220dbcaf05d15 = L.popup({&quot;maxWidth&quot;: &quot;100%&quot;});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_a3077dfa53023ebccf041b1f6d647d30 = $(`&lt;div id=&quot;html_a3077dfa53023ebccf041b1f6d647d30&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Moving Towards Stop: Yes&lt;/div&gt;`)[0];\n",
       "                popup_ea25f34ea9a3bc035df220dbcaf05d15.setContent(html_a3077dfa53023ebccf041b1f6d647d30);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_623549951b8d75a36be2e6db8abb1916.bindPopup(popup_ea25f34ea9a3bc035df220dbcaf05d15)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var marker_21d3224d46010fa5be88a551630e1e60 = L.marker(\n",
       "                [32.047676, 34.862758],\n",
       "                {}\n",
       "            ).addTo(map_9d2f5dc51a2a2f2e025514c9394e72f9);\n",
       "        \n",
       "    \n",
       "            var icon_f1204a56a2e0c34f4e96938244c8e04c = L.AwesomeMarkers.icon(\n",
       "                {&quot;extraClasses&quot;: &quot;fa-rotate-0&quot;, &quot;icon&quot;: &quot;info-sign&quot;, &quot;iconColor&quot;: &quot;white&quot;, &quot;markerColor&quot;: &quot;blue&quot;, &quot;prefix&quot;: &quot;glyphicon&quot;}\n",
       "            );\n",
       "            marker_21d3224d46010fa5be88a551630e1e60.setIcon(icon_f1204a56a2e0c34f4e96938244c8e04c);\n",
       "        \n",
       "    \n",
       "        var popup_69de902351677e708000e7861790537a = L.popup({&quot;maxWidth&quot;: &quot;100%&quot;});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_588c5e71ad0d96eb29010cf1e2f51776 = $(`&lt;div id=&quot;html_588c5e71ad0d96eb29010cf1e2f51776&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Moving Towards Stop: Yes&lt;/div&gt;`)[0];\n",
       "                popup_69de902351677e708000e7861790537a.setContent(html_588c5e71ad0d96eb29010cf1e2f51776);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_21d3224d46010fa5be88a551630e1e60.bindPopup(popup_69de902351677e708000e7861790537a)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var marker_3fe264241d48e9ca50a17a59397c8084 = L.marker(\n",
       "                [32.045978, 34.865734],\n",
       "                {}\n",
       "            ).addTo(map_9d2f5dc51a2a2f2e025514c9394e72f9);\n",
       "        \n",
       "    \n",
       "            var icon_3d728322757bfaa83a8bc92ea0fb9a8a = L.AwesomeMarkers.icon(\n",
       "                {&quot;extraClasses&quot;: &quot;fa-rotate-0&quot;, &quot;icon&quot;: &quot;info-sign&quot;, &quot;iconColor&quot;: &quot;white&quot;, &quot;markerColor&quot;: &quot;blue&quot;, &quot;prefix&quot;: &quot;glyphicon&quot;}\n",
       "            );\n",
       "            marker_3fe264241d48e9ca50a17a59397c8084.setIcon(icon_3d728322757bfaa83a8bc92ea0fb9a8a);\n",
       "        \n",
       "    \n",
       "        var popup_ae19bae90f2f93f235b20a22bc435c01 = L.popup({&quot;maxWidth&quot;: &quot;100%&quot;});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_fa4dc3cc27fb536552d60aa197cb210a = $(`&lt;div id=&quot;html_fa4dc3cc27fb536552d60aa197cb210a&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Moving Towards Stop: No&lt;/div&gt;`)[0];\n",
       "                popup_ae19bae90f2f93f235b20a22bc435c01.setContent(html_fa4dc3cc27fb536552d60aa197cb210a);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_3fe264241d48e9ca50a17a59397c8084.bindPopup(popup_ae19bae90f2f93f235b20a22bc435c01)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var marker_5c5f77249b1718f7013f8fd016207551 = L.marker(\n",
       "                [32.082661, 34.845048],\n",
       "                {}\n",
       "            ).addTo(map_9d2f5dc51a2a2f2e025514c9394e72f9);\n",
       "        \n",
       "    \n",
       "            var icon_15c036a476c93efe53eaf4529929208e = L.AwesomeMarkers.icon(\n",
       "                {&quot;extraClasses&quot;: &quot;fa-rotate-0&quot;, &quot;icon&quot;: &quot;info-sign&quot;, &quot;iconColor&quot;: &quot;white&quot;, &quot;markerColor&quot;: &quot;red&quot;, &quot;prefix&quot;: &quot;glyphicon&quot;}\n",
       "            );\n",
       "            marker_5c5f77249b1718f7013f8fd016207551.setIcon(icon_15c036a476c93efe53eaf4529929208e);\n",
       "        \n",
       "    \n",
       "            var marker_10e0596062a5dbda487dd2e80acea6d3 = L.marker(\n",
       "                [32.074823, 34.843553],\n",
       "                {}\n",
       "            ).addTo(map_9d2f5dc51a2a2f2e025514c9394e72f9);\n",
       "        \n",
       "    \n",
       "            var icon_e125ddb94916c7e11b77bf6af469aa40 = L.AwesomeMarkers.icon(\n",
       "                {&quot;extraClasses&quot;: &quot;fa-rotate-0&quot;, &quot;icon&quot;: &quot;info-sign&quot;, &quot;iconColor&quot;: &quot;white&quot;, &quot;markerColor&quot;: &quot;red&quot;, &quot;prefix&quot;: &quot;glyphicon&quot;}\n",
       "            );\n",
       "            marker_10e0596062a5dbda487dd2e80acea6d3.setIcon(icon_e125ddb94916c7e11b77bf6af469aa40);\n",
       "        \n",
       "    \n",
       "            var marker_f48bcc8abf17256400ae61ae26f7e8e9 = L.marker(\n",
       "                [32.067809, 34.83984],\n",
       "                {}\n",
       "            ).addTo(map_9d2f5dc51a2a2f2e025514c9394e72f9);\n",
       "        \n",
       "    \n",
       "            var icon_bc37c77057a3486a8e1c8af09f2f7147 = L.AwesomeMarkers.icon(\n",
       "                {&quot;extraClasses&quot;: &quot;fa-rotate-0&quot;, &quot;icon&quot;: &quot;info-sign&quot;, &quot;iconColor&quot;: &quot;white&quot;, &quot;markerColor&quot;: &quot;red&quot;, &quot;prefix&quot;: &quot;glyphicon&quot;}\n",
       "            );\n",
       "            marker_f48bcc8abf17256400ae61ae26f7e8e9.setIcon(icon_bc37c77057a3486a8e1c8af09f2f7147);\n",
       "        \n",
       "    \n",
       "            var marker_1127ab88f5dffbf15e736a223f95711a = L.marker(\n",
       "                [32.065377, 34.845842],\n",
       "                {}\n",
       "            ).addTo(map_9d2f5dc51a2a2f2e025514c9394e72f9);\n",
       "        \n",
       "    \n",
       "            var icon_a385a75467181b1a2827f29a9462291e = L.AwesomeMarkers.icon(\n",
       "                {&quot;extraClasses&quot;: &quot;fa-rotate-0&quot;, &quot;icon&quot;: &quot;info-sign&quot;, &quot;iconColor&quot;: &quot;white&quot;, &quot;markerColor&quot;: &quot;red&quot;, &quot;prefix&quot;: &quot;glyphicon&quot;}\n",
       "            );\n",
       "            marker_1127ab88f5dffbf15e736a223f95711a.setIcon(icon_a385a75467181b1a2827f29a9462291e);\n",
       "        \n",
       "    \n",
       "            var marker_881533902cd6c7f6a69ccc63c44be21c = L.marker(\n",
       "                [32.065509, 34.850234],\n",
       "                {}\n",
       "            ).addTo(map_9d2f5dc51a2a2f2e025514c9394e72f9);\n",
       "        \n",
       "    \n",
       "            var icon_2b8addf32016e623c9c9bc95e010958f = L.AwesomeMarkers.icon(\n",
       "                {&quot;extraClasses&quot;: &quot;fa-rotate-0&quot;, &quot;icon&quot;: &quot;info-sign&quot;, &quot;iconColor&quot;: &quot;white&quot;, &quot;markerColor&quot;: &quot;red&quot;, &quot;prefix&quot;: &quot;glyphicon&quot;}\n",
       "            );\n",
       "            marker_881533902cd6c7f6a69ccc63c44be21c.setIcon(icon_2b8addf32016e623c9c9bc95e010958f);\n",
       "        \n",
       "    \n",
       "            var marker_7bd1fac08b60c80a7c91d283418c9e59 = L.marker(\n",
       "                [32.0654, 34.855732],\n",
       "                {}\n",
       "            ).addTo(map_9d2f5dc51a2a2f2e025514c9394e72f9);\n",
       "        \n",
       "    \n",
       "            var icon_e2a5cd3f43136918fc1975364539a41a = L.AwesomeMarkers.icon(\n",
       "                {&quot;extraClasses&quot;: &quot;fa-rotate-0&quot;, &quot;icon&quot;: &quot;info-sign&quot;, &quot;iconColor&quot;: &quot;white&quot;, &quot;markerColor&quot;: &quot;red&quot;, &quot;prefix&quot;: &quot;glyphicon&quot;}\n",
       "            );\n",
       "            marker_7bd1fac08b60c80a7c91d283418c9e59.setIcon(icon_e2a5cd3f43136918fc1975364539a41a);\n",
       "        \n",
       "    \n",
       "            var marker_27fb2b8afffe3633890ebd6a7c146b54 = L.marker(\n",
       "                [32.063529, 34.857014],\n",
       "                {}\n",
       "            ).addTo(map_9d2f5dc51a2a2f2e025514c9394e72f9);\n",
       "        \n",
       "    \n",
       "            var icon_a5440eb3dcf1667d9b8183474c578eba = L.AwesomeMarkers.icon(\n",
       "                {&quot;extraClasses&quot;: &quot;fa-rotate-0&quot;, &quot;icon&quot;: &quot;info-sign&quot;, &quot;iconColor&quot;: &quot;white&quot;, &quot;markerColor&quot;: &quot;red&quot;, &quot;prefix&quot;: &quot;glyphicon&quot;}\n",
       "            );\n",
       "            marker_27fb2b8afffe3633890ebd6a7c146b54.setIcon(icon_a5440eb3dcf1667d9b8183474c578eba);\n",
       "        \n",
       "    \n",
       "            var marker_15a33a4a649a49cd0865a539865fa708 = L.marker(\n",
       "                [32.063438, 34.861389],\n",
       "                {}\n",
       "            ).addTo(map_9d2f5dc51a2a2f2e025514c9394e72f9);\n",
       "        \n",
       "    \n",
       "            var icon_9c14cdc35206febd5d51c12ddaf89920 = L.AwesomeMarkers.icon(\n",
       "                {&quot;extraClasses&quot;: &quot;fa-rotate-0&quot;, &quot;icon&quot;: &quot;info-sign&quot;, &quot;iconColor&quot;: &quot;white&quot;, &quot;markerColor&quot;: &quot;red&quot;, &quot;prefix&quot;: &quot;glyphicon&quot;}\n",
       "            );\n",
       "            marker_15a33a4a649a49cd0865a539865fa708.setIcon(icon_9c14cdc35206febd5d51c12ddaf89920);\n",
       "        \n",
       "    \n",
       "            var marker_f3a0c57cbaeb7d1c36f6df8ec56c57e5 = L.marker(\n",
       "                [32.060705, 34.863046],\n",
       "                {}\n",
       "            ).addTo(map_9d2f5dc51a2a2f2e025514c9394e72f9);\n",
       "        \n",
       "    \n",
       "            var icon_1124b7a1e2c03d3c232a5b8f7bea96a1 = L.AwesomeMarkers.icon(\n",
       "                {&quot;extraClasses&quot;: &quot;fa-rotate-0&quot;, &quot;icon&quot;: &quot;info-sign&quot;, &quot;iconColor&quot;: &quot;white&quot;, &quot;markerColor&quot;: &quot;red&quot;, &quot;prefix&quot;: &quot;glyphicon&quot;}\n",
       "            );\n",
       "            marker_f3a0c57cbaeb7d1c36f6df8ec56c57e5.setIcon(icon_1124b7a1e2c03d3c232a5b8f7bea96a1);\n",
       "        \n",
       "    \n",
       "            var marker_c787214a5df56af7b375cea21c1355ba = L.marker(\n",
       "                [32.057814, 34.864174],\n",
       "                {}\n",
       "            ).addTo(map_9d2f5dc51a2a2f2e025514c9394e72f9);\n",
       "        \n",
       "    \n",
       "            var icon_4c385a02205dc4c39565e82a13d0ad2d = L.AwesomeMarkers.icon(\n",
       "                {&quot;extraClasses&quot;: &quot;fa-rotate-0&quot;, &quot;icon&quot;: &quot;info-sign&quot;, &quot;iconColor&quot;: &quot;white&quot;, &quot;markerColor&quot;: &quot;red&quot;, &quot;prefix&quot;: &quot;glyphicon&quot;}\n",
       "            );\n",
       "            marker_c787214a5df56af7b375cea21c1355ba.setIcon(icon_4c385a02205dc4c39565e82a13d0ad2d);\n",
       "        \n",
       "    \n",
       "            var marker_d5223acb774cbf5b8e2818d4b48976c9 = L.marker(\n",
       "                [32.05514, 34.863882],\n",
       "                {}\n",
       "            ).addTo(map_9d2f5dc51a2a2f2e025514c9394e72f9);\n",
       "        \n",
       "    \n",
       "            var icon_0ce32cd1a153d0adf6bd02c37298b8e8 = L.AwesomeMarkers.icon(\n",
       "                {&quot;extraClasses&quot;: &quot;fa-rotate-0&quot;, &quot;icon&quot;: &quot;info-sign&quot;, &quot;iconColor&quot;: &quot;white&quot;, &quot;markerColor&quot;: &quot;red&quot;, &quot;prefix&quot;: &quot;glyphicon&quot;}\n",
       "            );\n",
       "            marker_d5223acb774cbf5b8e2818d4b48976c9.setIcon(icon_0ce32cd1a153d0adf6bd02c37298b8e8);\n",
       "        \n",
       "    \n",
       "            var marker_5b4a254fc965d8b7ff4d3a1d0e826029 = L.marker(\n",
       "                [32.04807, 34.86513],\n",
       "                {}\n",
       "            ).addTo(map_9d2f5dc51a2a2f2e025514c9394e72f9);\n",
       "        \n",
       "    \n",
       "            var icon_5f0173cdb353c380b73b7a1e5b7763b9 = L.AwesomeMarkers.icon(\n",
       "                {&quot;extraClasses&quot;: &quot;fa-rotate-0&quot;, &quot;icon&quot;: &quot;info-sign&quot;, &quot;iconColor&quot;: &quot;white&quot;, &quot;markerColor&quot;: &quot;red&quot;, &quot;prefix&quot;: &quot;glyphicon&quot;}\n",
       "            );\n",
       "            marker_5b4a254fc965d8b7ff4d3a1d0e826029.setIcon(icon_5f0173cdb353c380b73b7a1e5b7763b9);\n",
       "        \n",
       "    \n",
       "            var marker_e5be03cf16ee5fd9b6a178852aa1420a = L.marker(\n",
       "                [32.049525, 34.856072],\n",
       "                {}\n",
       "            ).addTo(map_9d2f5dc51a2a2f2e025514c9394e72f9);\n",
       "        \n",
       "    \n",
       "            var icon_a8f01fac7fe4cdce7a291b31fa80bd88 = L.AwesomeMarkers.icon(\n",
       "                {&quot;extraClasses&quot;: &quot;fa-rotate-0&quot;, &quot;icon&quot;: &quot;info-sign&quot;, &quot;iconColor&quot;: &quot;white&quot;, &quot;markerColor&quot;: &quot;red&quot;, &quot;prefix&quot;: &quot;glyphicon&quot;}\n",
       "            );\n",
       "            marker_e5be03cf16ee5fd9b6a178852aa1420a.setIcon(icon_a8f01fac7fe4cdce7a291b31fa80bd88);\n",
       "        \n",
       "    \n",
       "            var marker_a52b31409b946825c7e4721877a29c75 = L.marker(\n",
       "                [32.048301, 34.860287],\n",
       "                {}\n",
       "            ).addTo(map_9d2f5dc51a2a2f2e025514c9394e72f9);\n",
       "        \n",
       "    \n",
       "            var icon_677e100541fb982bb780617da4797c6c = L.AwesomeMarkers.icon(\n",
       "                {&quot;extraClasses&quot;: &quot;fa-rotate-0&quot;, &quot;icon&quot;: &quot;info-sign&quot;, &quot;iconColor&quot;: &quot;white&quot;, &quot;markerColor&quot;: &quot;red&quot;, &quot;prefix&quot;: &quot;glyphicon&quot;}\n",
       "            );\n",
       "            marker_a52b31409b946825c7e4721877a29c75.setIcon(icon_677e100541fb982bb780617da4797c6c);\n",
       "        \n",
       "    \n",
       "            var marker_fe22c29fa71e89c6603cb3dd6306f210 = L.marker(\n",
       "                [32.045211, 34.8658],\n",
       "                {}\n",
       "            ).addTo(map_9d2f5dc51a2a2f2e025514c9394e72f9);\n",
       "        \n",
       "    \n",
       "            var icon_2aa0ebbc64394c06f3614577f1bb743d = L.AwesomeMarkers.icon(\n",
       "                {&quot;extraClasses&quot;: &quot;fa-rotate-0&quot;, &quot;icon&quot;: &quot;info-sign&quot;, &quot;iconColor&quot;: &quot;white&quot;, &quot;markerColor&quot;: &quot;red&quot;, &quot;prefix&quot;: &quot;glyphicon&quot;}\n",
       "            );\n",
       "            marker_fe22c29fa71e89c6603cb3dd6306f210.setIcon(icon_2aa0ebbc64394c06f3614577f1bb743d);\n",
       "        \n",
       "    \n",
       "            var poly_line_eb0465b9fdb92d25e15f724764dc4d48 = L.polyline(\n",
       "                [[32.0825, 34.845043], [32.07529, 34.843635], [32.068443, 34.840351], [32.064876, 34.84473], [32.066123, 34.849441], [32.065547, 34.854652], [32.063648, 34.857154], [32.063495, 34.861362], [32.060867, 34.86301], [32.057689, 34.864395], [32.054138, 34.864418], [32.047882, 34.865272], [32.049659, 34.856235], [32.047676, 34.862758], [32.045978, 34.865734]],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;blue&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;blue&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;noClip&quot;: false, &quot;opacity&quot;: 1.0, &quot;smoothFactor&quot;: 1.0, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_9d2f5dc51a2a2f2e025514c9394e72f9);\n",
       "        \n",
       "    \n",
       "            var poly_line_59321b515360eac55cdcef3a2c975f2d = L.polyline(\n",
       "                [[32.082661, 34.845048], [32.074823, 34.843553], [32.067809, 34.83984], [32.065377, 34.845842], [32.065509, 34.850234], [32.0654, 34.855732], [32.063529, 34.857014], [32.063438, 34.861389], [32.060705, 34.863046], [32.057814, 34.864174], [32.05514, 34.863882], [32.04807, 34.86513], [32.049525, 34.856072], [32.048301, 34.860287], [32.045211, 34.8658]],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;red&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;red&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;noClip&quot;: false, &quot;opacity&quot;: 1.0, &quot;smoothFactor&quot;: 1.0, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_9d2f5dc51a2a2f2e025514c9394e72f9);\n",
       "        \n",
       "&lt;/script&gt;\n",
       "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x18c241250>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_journey('2023-01-01-215456', results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bus Arrival Time Analysis\n",
    "\n",
    "In this Python code snippet, we're performing several key steps to analyze bus arrival times:\n",
    "\n",
    "1. **Calculate Arrival Time Difference**: We first calculate the difference between the estimated arrival time and the scheduled arrival time for each bus. This is done by subtracting the `scheduled_arrival_time` from the `estimated_arrival_time`. The result is stored in a new column in our DataFrame, `results`, named `arrival_time_diff`.\n",
    "\n",
    "2. **Define Bus Classification Function**: We then define a function, `classify_bus`, that takes in the arrival time difference and a threshold (in minutes) as parameters. This function classifies the bus status into one of four categories:\n",
    "\n",
    "   - 'Missing': If the arrival time difference is null.\n",
    "   - 'Late': If the bus arrived later than the scheduled time by more than the threshold.\n",
    "   - 'Early': If the bus arrived earlier than the scheduled time by more than the threshold.\n",
    "   - 'On Time': If the bus arrived within the threshold window.\n",
    "\n",
    "3. **Apply Classification Function**: We set the threshold to 3 minutes and apply the `classify_bus` function to the `arrival_time_diff` column of our DataFrame. The resulting bus status for each row is stored in a new column, `bus_status`.\n",
    "\n",
    "4. **Group and Count Bus Status**: Finally, we group the DataFrame by `siri_journey_ref` (which represents a unique bus journey) and `bus_status`, and count the size of each group. This gives us a count of each bus status category for each unique bus journey. The result is stored in `bus_stats`.\n",
    "\n",
    "This preprocessing step is key as it allows us to categorize bus arrival times and understand the distribution of 'Late', 'Early', 'On Time', and 'Missing' statuses across different bus journeys. This categorized data can then be used for further analysis, such as identifying patterns or trends in bus arrival times, or investigating the factors that might influence a bus's punctuality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mKernel is dead. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def classify_bus(arrival_time_diff, threshold):\n",
    "    if pd.isnull(arrival_time_diff):\n",
    "        return 'Missing'\n",
    "    elif arrival_time_diff > pd.Timedelta(minutes=threshold):\n",
    "        return 'Late'\n",
    "    elif arrival_time_diff < -pd.Timedelta(minutes=threshold):\n",
    "        return 'Early'\n",
    "    else:\n",
    "        return 'On Time'\n",
    "\n",
    "threshold = 3\n",
    "def calculate_bus_stats_and_update_df(results, threshold):\n",
    "    results['bus_status'] = results['arrival_time_diff'].apply(lambda x: classify_bus(x, threshold))\n",
    "    bus_stats = results.groupby(['siri_journey_ref', 'bus_status']).size()\n",
    "    return bus_stats, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_stats, results = calculate_bus_stats_and_update_df(results, threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Late Bus Stops\n",
    "\n",
    "The Python code snippet performs the following operations:\n",
    "\n",
    "1. **Filter the DataFrame**: The `results` DataFrame is filtered to only include rows where the `bus_status` is 'Late'. This filtered DataFrame, `late_buses`, includes all instances where a bus was late to a stop, regardless of whether it's the same bus or the same journey.\n",
    "\n",
    "2. **Analyze the 'recorded_at_time' column**: The `recorded_at_time` column of the `late_buses` DataFrame is analyzed to understand the distribution of late bus stops throughout the day. This is done by extracting the hour from the `recorded_at_time` and creating a histogram.\n",
    "\n",
    "3. **Plot Histogram**: A histogram is plotted to visualize the number of late bus stops for each hour of the day. The x-axis represents the hour of the day (24-hour format), and the y-axis represents the number of late bus stops.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mKernel is dead. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def plot_late_buses(results):\n",
    "    late_buses = results[results['bus_status'] == 'Late']\n",
    "    late_buses['recorded_at_time'].dt.hour.hist()\n",
    "    plt.title('Time of Day for Late Buses')\n",
    "    plt.xlabel('Hour of Day')\n",
    "    plt.ylabel('Number of Late Buses')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_late_buses(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing and Analysis\n",
    "\n",
    "The following Python code block performs several data preprocessing steps on a DataFrame named `results`. Here's a breakdown of what each section does:\n",
    "\n",
    "1. **Bus Status Conversion**: Converts the 'bus_status' column to numerical values, where 'Late' is represented as 1 and other statuses as 0.\n",
    "\n",
    "2. **Time Feature Extraction**: Extracts day of the week and hour from 'gtfs_start_time', 'gtfs_end_time', and 'recorded_at_time' columns.\n",
    "\n",
    "3. **Correlation Calculation**: Calculates the correlation of numerical columns with 'bus_status_num' and sorts them.\n",
    "\n",
    "4. **Pivot Table Creation**: Creates pivot tables for 'recorded_at_time', 'gtfs_start_time', and 'gtfs_end_time' with 'bus_status_num' as values. The pivot tables are indexed by day of the week and hour, and missing values are filled with 0.\n",
    "\n",
    "The pivot tables provide a summary of the average bus status (late or not) for each hour of each day of the week, for the start time, end time, and recorded time. This can be useful for identifying patterns or trends in bus lateness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mKernel is dead. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def process_results(results):\n",
    "    results['bus_status_num'] = results['bus_status'].apply(lambda x: 1 if x == 'Late' else 0)\n",
    "\n",
    "    results['gtfs_start_time__day_of_week'] = results['gtfs_start_time'].dt.dayofweek\n",
    "    results['gtfs_start_time__hour'] = results['gtfs_start_time'].dt.hour\n",
    "\n",
    "    results['gtfs_end_time__day_of_week'] = results['gtfs_end_time'].dt.dayofweek\n",
    "    results['gtfs_end_time__hour'] = results['gtfs_end_time'].dt.hour\n",
    "\n",
    "    results['recorded_at_time__day_of_week'] = results['recorded_at_time'].dt.dayofweek\n",
    "    results['recorded_at_time__hour'] = results['recorded_at_time'].dt.hour\n",
    "\n",
    "    numerical_cols = ['gtfs_start_time__day_of_week', 'gtfs_start_time__hour', 'gtfs_end_time__day_of_week', 'gtfs_end_time__hour', 'gtfs_stop_sequence', 'recorded_at_time__day_of_week', 'recorded_at_time__hour', 'closest_location_bearing', 'distance_from_stop', 'bus_status_num', 'siri_vehicle_ref']\n",
    "\n",
    "    correlations = results[numerical_cols].corr()['bus_status_num'].sort_values()\n",
    "\n",
    "    return results, correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "results, correlations = process_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap Visualization\n",
    "\n",
    "The Python code block below generates heatmaps for the pivot tables created in the previous step. The heatmaps visualize the average bus status (late or not) for each hour of each day of the week, for the start time, end time, and recorded time.\n",
    "\n",
    "Three sets of heatmaps are created:\n",
    "\n",
    "1. **Recorded Time Heatmaps**: These heatmaps use the pivot table indexed by the day of the week and hour of the 'recorded_at_time'. Each heatmap represents a day of the week.\n",
    "\n",
    "2. **Start Time Heatmaps**: These heatmaps use the pivot table indexed by the day of the week and hour of the 'gtfs_start_time'. Each heatmap represents a day of the week.\n",
    "\n",
    "3. **End Time Heatmaps**: These heatmaps use the pivot table indexed by the day of the week and hour of the 'gtfs_end_time'. Each heatmap represents a day of the week.\n",
    "\n",
    "The color gradient in the heatmaps represents the average bus status, with lighter colors indicating a higher likelihood of the bus being late. This visualization can help identify patterns or trends in bus lateness across different times and days.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mKernel is dead. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def create_pivot_tables(results):\n",
    "    def create_pivot_table(df, index_cols, value_col):\n",
    "        pivot_table = df.pivot_table(index=index_cols, values=value_col, aggfunc='mean')\n",
    "        all_days_of_week = sorted(df[index_cols[0]].unique())\n",
    "        all_hours = range(24)\n",
    "        index = pd.MultiIndex.from_product([all_days_of_week, all_hours], names=index_cols)\n",
    "        pivot_table = pivot_table.reindex(index)\n",
    "        pivot_table.fillna(0, inplace=True)\n",
    "        return pivot_table\n",
    "\n",
    "    recorded_time_pivot = create_pivot_table(results, ['recorded_at_time__day_of_week', 'recorded_at_time__hour'], 'bus_status_num')\n",
    "    start_time_pivot = create_pivot_table(results, ['gtfs_start_time__day_of_week', 'gtfs_start_time__hour'], 'bus_status_num')\n",
    "    end_time_pivot = create_pivot_table(results, ['gtfs_end_time__day_of_week', 'gtfs_end_time__hour'], 'bus_status_num')\n",
    "\n",
    "    return recorded_time_pivot, start_time_pivot, end_time_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "recorded_time_pivot, start_time_pivot, end_time_pivot = create_pivot_tables(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mKernel is dead. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def plot_heatmaps(pivot_tables, titles):\n",
    "    days_of_week = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "    for pivot_table, title in zip(pivot_tables, titles):\n",
    "        fig, axs = plt.subplots(2, 4, figsize=(20, 10))\n",
    "\n",
    "        # Remove the extra subplot\n",
    "        fig.delaxes(axs[1,3])\n",
    "\n",
    "        for i, day in enumerate(days_of_week):\n",
    "            sns.heatmap(pivot_table.loc[i], cmap='viridis', ax=axs[i//4, i%4])\n",
    "            axs[i//4, i%4].set_title(f'Heatmap for {day} - {title}')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmaps([recorded_time_pivot, start_time_pivot, end_time_pivot], ['recorded_at_time', 'gtfs_start_time', 'gtfs_end_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bus Delays by City\n",
    "\n",
    "In this analysis, we are investigating the delay of buses across different cities.\n",
    "\n",
    "The Python code provided creates a pivot table from the `results` DataFrame, using the 'gtfs_stop_city' column as the index and the 'bus_status_num' column as the values. The aggregation function used is 'mean', which gives us the average delay for each city.\n",
    "\n",
    "A function `reverse_string(s)` is defined and applied to the index of the pivot table to reverse the order of the text.\n",
    "\n",
    "A heatmap is then created using seaborn's `sns.heatmap()` function, visualizing the average delay of buses in different cities. The color intensity in the heatmap represents the magnitude of the delay.\n",
    "\n",
    "By examining this heatmap, we can identify which cities experience the most significant bus delays.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mKernel is dead. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def plot_city_heatmap(results):\n",
    "    pivot_table_city = results.pivot_table(index='gtfs_stop_city', values='bus_status_num', aggfunc='mean')\n",
    "\n",
    "    def reverse_string(s):\n",
    "        return s[::-1]\n",
    "\n",
    "    pivot_table_city.index = pivot_table_city.index.map(reverse_string)\n",
    "\n",
    "    # Create the heatmap\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(pivot_table_city, annot=True, cmap='coolwarm')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_city_heatmap(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Analysis to the Entire Dataset\n",
    "\n",
    "In this section, we will apply the analysis we have developed to the entire dataset. Given the large size of the data (approximately 800GB), we will process the data in batches. This approach allows us to efficiently handle the data without overloading the memory.\n",
    "\n",
    "The steps we will follow are:\n",
    "\n",
    "1. **Batch Creation**: We will create data batches, ensuring that each batch does not exceed a specified size limit. To maintain data integrity, we will ensure that all related lines (i.e., lines with the same 'siri_journey_ref') are included in the same batch.\n",
    "\n",
    "2. **Batch Analysis**: We will apply our analysis to each batch individually. This includes any data cleaning, transformation, and statistical analysis we have previously defined.\n",
    "\n",
    "3. **Results Aggregation**: After analyzing each batch, we will aggregate the results. This could involve combining the results into a single data structure, or it could involve saving the results of each batch's analysis to disk.\n",
    "\n",
    "By processing the data in batches, we can scale our analysis to handle large datasets that would not otherwise fit into memory. Let's get started!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Creation Function\n",
    "\n",
    "In this cell, we define a function `create_batch_df` to create data batches from the large dataset. The function takes the following parameters:\n",
    "\n",
    "- `csv_dir`: The directory where the CSV files are stored.\n",
    "- `batch_size_gb`: The maximum size of each batch in gigabytes.\n",
    "- `last_journey_refs`: A set of 'siri_journey_ref' values that were included in the last batch and should be excluded from the current batch.\n",
    "- `start_file`: The file to start reading from. If not specified, reading starts from the first file in the directory.\n",
    "- `start_pos`: The position in the start file to start reading from.\n",
    "\n",
    "The function works as follows:\n",
    "\n",
    "1. It initializes an empty DataFrame for the batch and a set to keep track of the 'siri_journey_ref' values in the current batch.\n",
    "\n",
    "2. It iterates over each file in the directory, starting from the `start_file` if specified.\n",
    "\n",
    "3. For each file, it creates an iterator for the chunks in the file and reads the first chunk.\n",
    "\n",
    "4. If there are any `last_journey_refs`, it excludes them from the chunk.\n",
    "\n",
    "5. It then enters a loop where it adds the chunk to the batch if it doesn't exceed the `batch_size_gb`. If the batch size is exceeded, it adds only the rows with the same 'siri_journey_ref' as in the current batch.\n",
    "\n",
    "6. The function returns the batch DataFrame, the set of 'siri_journey_ref' values in the current batch, the next chunk, the iterator for the next chunks, the next file, and the index of the next file.\n",
    "\n",
    "By using this function, we can create manageable batches from the large dataset while ensuring that all related lines are included in the same batch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mKernel is dead. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "import uuid\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "def create_batch_df(parquet_dir, batch_size_gb, last_batch_journey_refs=None, start_file=None, start_pos=0):\n",
    "    # Convert batch size from GB to bytes\n",
    "    batch_size_bytes = batch_size_gb * 1024 * 1024 * 1024\n",
    "\n",
    "    # Get a list of all output Parquet files\n",
    "    parquet_files = glob.glob(f'{parquet_dir}/output_*.parquet')\n",
    "    parquet_files.sort(key=extract_number)\n",
    "\n",
    "    # If a start file is specified, start from this file\n",
    "    if start_file is not None:\n",
    "        parquet_files = parquet_files[parquet_files.index(start_file):]\n",
    "\n",
    "    # Initialize an empty DataFrame for the batch\n",
    "    batch_df = pd.DataFrame()\n",
    "\n",
    "    # Initialize a set to keep track of the 'siri_journey_ref' values in the current batch\n",
    "    current_journey_refs = set()\n",
    "\n",
    "    for file in parquet_files:\n",
    "        # Create an iterator for the chunks in the Parquet file\n",
    "        parquet_file = pq.ParquetFile(file)\n",
    "        chunk_iter = parquet_file.iter_batches(batch_size=100000)  # Adjust batch size as needed\n",
    "\n",
    "        # Read the first chunk and convert it to a DataFrame\n",
    "        chunk = pd.DataFrame(next(chunk_iter).to_pandas())\n",
    "\n",
    "        # If there are any last journey refs, exclude them from the chunk\n",
    "        if last_batch_journey_refs is not None:\n",
    "            chunk = chunk[~chunk['siri_journey_ref'].isin(last_batch_journey_refs)]\n",
    "        while True:\n",
    "            # Add the chunk to the batch if it doesn't exceed the batch size\n",
    "            if (batch_df.memory_usage(index=True, deep=True).sum() + chunk.memory_usage(index=True, deep=True).sum()) <= batch_size_bytes:\n",
    "                batch_df = pd.concat([batch_df, chunk])\n",
    "                current_journey_refs.update(chunk['siri_journey_ref'].unique())\n",
    "\n",
    "            else:\n",
    "                # If the batch size is exceeded, add only the rows with the same 'siri_journey_ref' as in the current batch\n",
    "                current_journey_refs_in_chunk = chunk['siri_journey_ref'].isin(current_journey_refs)\n",
    "                if current_journey_refs_in_chunk.any():\n",
    "                    batch_df = pd.concat([batch_df, chunk[current_journey_refs_in_chunk]])\n",
    "                    chunk = chunk[~current_journey_refs_in_chunk]\n",
    "\n",
    "                # Return the current DataFrame and the set of 'siri_journey_ref' values\n",
    "                return batch_df, current_journey_refs, chunk, chunk_iter, file, parquet_files.index(file)\n",
    "\n",
    "            # Try to read the next chunk\n",
    "            try:\n",
    "                chunk = pd.DataFrame(next(chunk_iter).to_pandas())\n",
    "            except StopIteration:\n",
    "                break\n",
    "\n",
    "    # If all files have been processed, return the current DataFrame and the set of 'siri_journey_ref' values\n",
    "    return batch_df, current_journey_refs, None, None, None, None\n",
    "\n",
    "def process_batch_df(batch_df):\n",
    "    # Process the DataFrame\n",
    "    df_bus_journey_stops, df_locations = process_dataframe(batch_df)\n",
    "\n",
    "    print(f'Processed {len(df_bus_journey_stops)} bus journey stops and {len(df_locations)} locations.')\n",
    "    # Process the locations\n",
    "    df_locations = process_locations(df_locations)\n",
    "\n",
    "    # Calculate the arrival times\n",
    "    results = calculate_arrival_times(df_locations, df_bus_journey_stops, bearing_threshold=30)\n",
    "\n",
    "    print(f'Calculated arrival times for {len(results)} stops.')\n",
    "    # Calculate the bus stats and update the DataFrame\n",
    "    _, results = calculate_bus_stats_and_update_df(results, threshold=3)\n",
    "\n",
    "    # Process the results\n",
    "    results = process_results(results)\n",
    "\n",
    "    return results\n",
    "\n",
    "def save_processed_batch(batch_df):\n",
    "    batch_num = uuid.uuid4()\n",
    "    output_file = f'{DATA_FOLDER}/processed_batches/processed_batch_{batch_num}.parquet'\n",
    "    print(f'Saving processed batch to {output_file}')\n",
    "    batch_df.to_parquet(output_file, index=False, engine='fastparquet')    \n",
    "\n",
    "def process_batches_parallel(batch_dfs):\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        results = list(executor.map(process_batch_df, batch_dfs))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def process_parquet_files(parquet_dir, batch_size_gb, num_batches):\n",
    "    last_batch_journey_refs = None\n",
    "    start_file = None\n",
    "    start_pos = 0\n",
    "\n",
    "    while True:\n",
    "        batches = []\n",
    "        for _ in range(num_batches):\n",
    "            batch_df, last_batch_journey_refs, remaining_chunk, chunk_iter, start_file, start_pos = create_batch_df(parquet_dir, batch_size_gb, last_batch_journey_refs, start_file, start_pos)\n",
    "            batches.append(batch_df)\n",
    "\n",
    "            # If there are no more files to process, break the loop\n",
    "            if start_file is None:\n",
    "                break\n",
    "\n",
    "        if not batches:\n",
    "            break\n",
    "\n",
    "        processes_batches =  process_batches_parallel(batches)\n",
    "\n",
    "        for batch, _ in processes_batches:\n",
    "            save_processed_batch(batch)\n",
    "\n",
    "        batches.clear()\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_df, _, _, _, _, _ = create_batch_df(f'{DATA_FOLDER}/concatenated_data_parquet', 0.6)\n",
    "\n",
    "process_batch_df(batch_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 200020 bus journey stops and 200149 locations.\n",
      "Processed 242628 bus journey stops and 242841 locations.\n",
      "Processed 248004 bus journey stops and 248257 locations.\n",
      "Calculated arrival times for 851992 stops.\n",
      "Calculated arrival times for 1714910 stops.\n",
      "Calculated arrival times for 1089802 stops.\n",
      "Saving processed batch to ./2023_siri_data/processed_batches/processed_batch_b5ad214c-92b9-438c-9b78-cb02ab5bf1dd.parquet\n",
      "Saving processed batch to ./2023_siri_data/processed_batches/processed_batch_3f45461e-9520-4d46-8e2b-0dda34fb34a4.parquet\n",
      "Saving processed batch to ./2023_siri_data/processed_batches/processed_batch_ec9b8a5e-95bc-480a-8429-7092adb5d3aa.parquet\n",
      "Processed 199889 bus journey stops and 199995 locations.\n",
      "Processed 199889 bus journey stops and 199995 locations.\n",
      "Processed 233282 bus journey stops and 233629 locations.\n"
     ]
    }
   ],
   "source": [
    "process_parquet_files(f'{DATA_FOLDER}/concatenated_data_parquet', 0.4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch DataFrame shape: (100718, 34)\n",
      "Batch size in GB: 0.1472242148593068\n"
     ]
    }
   ],
   "source": [
    "# Specify the directory where your Parquet files are located\n",
    "parquet_dir = f'{DATA_FOLDER}/concatenated_data_parquet'\n",
    "\n",
    "# Create a batch of 1GB\n",
    "batch_df, current_journey_refs, chunk, chunk_iter, file, file_index = create_batch_df(parquet_dir, batch_size_gb=0.2)\n",
    "\n",
    "print(f'Batch DataFrame shape: {batch_df.shape}')\n",
    "\n",
    "print(f'Batch size in GB: {batch_df.memory_usage(index=True, deep=True).sum() / 1024**3}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "\n",
    "def profile_process_batch_df():\n",
    "\n",
    "    # Use cProfile to profile the function\n",
    "    profiler = cProfile.Profile()\n",
    "    profiler.enable()\n",
    "\n",
    "    # Call the function you want to profile\n",
    "    process_batch_df(batch_df)\n",
    "\n",
    "    # Disable the profiler after your function call\n",
    "    profiler.disable()\n",
    "\n",
    "    # Print the stats\n",
    "    profiler.print_stats()\n",
    "\n",
    "# Call the profiling function\n",
    "profile_process_batch_df()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
